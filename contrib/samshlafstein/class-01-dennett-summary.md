# Reaction to Dennett Article 

In his article, Dennett draws a comparison between counterfeit currency and counterfeit online personas. Dennett uses this comparison to warn about the societal ramifications of counterfeit online personas and also to make recommendations how to best deter misuse of AI. Dennett advocates for enabling watermarks that demarcates AI generated content along with a host of legal penalties for malovent use of AI. I agree with Daniel's points, but find that his approach to countering the issue is incomplete. I think the issue of online personas requires a two-pronged approach: detterence must be accompanied with educational measures that better informs users-- of all ages-- what is AI and what is not. One pitfall of Daniels solution is that AI laws and companies are not neccessarily uniform across countries; for example, Russia, where many of these AI bots are propeggated, are unlikely to regulate given the political salience of these bots. Measures that inform users on how to detect AI content should be integrated onto social media platforms that are prone to profilerate bot content. This way, social media users will be better informed and savy to those who manage to get around Dennet's proposed barriers. Another potential issue with Dennet's suggestion is that there is little incentive for actors to implement such protective measures. I would not be surprised if X (formerly twitter) is aware of high bot usage on their platform but is looking the other way in an attempt to inflate user numers. I also could foresee companies using fake AI people to promote products, in which case there are 
